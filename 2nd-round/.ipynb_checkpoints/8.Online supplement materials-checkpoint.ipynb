{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H:\\Anaconda\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import pickle\n",
    "pl.rcParams.update({'font.size': 15, 'font.family': 'STIXGeneral', 'mathtext.fontset': 'stix'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import time\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "u = \"C:/Users/XIAOYU/PycharmProjects/A-fast-method/auto_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_peak_1 = np.load(u +\"estimate_gnm_random_graph(10000,30000)_Peak-1.npy\")\n",
    "coeff_peak0 =  np.load(u +\"estimate_gnm_random_graph(10000,30000)_Peak0.npy\")\n",
    "coeff_peak1 = np.load(u +\"estimate_gnm_random_graph(10000,30000)_Peak1.npy\")\n",
    "coeff_peak2 = np.load(u +\"estimate_gnm_random_graph(10000,30000)_Peak2.npy\")\n",
    "coeff_peak3 = np.load(u +\"estimate_gnm_random_graph(10000,30000)_Peak3.npy\")\n",
    "coeff_peak4 = np.load(u +\"estimate_gnm_random_graph(10000,30000)_Peak4.npy\")\n",
    "coeff_peak5 = np.load(u +\"estimate_gnm_random_graph(10000,30000)_Peak5.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_cont = [coeff_peak_1, coeff_peak0, coeff_peak1, coeff_peak2, coeff_peak3, coeff_peak4, coeff_peak5]\n",
    "title_cont = ['P-1', 'P', 'P+1', 'P+2', 'P+3', 'P+4', 'P+5']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) $R^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-1 \t0.9996, 0.0004\n",
      "P \t0.9995, 0.0003\n",
      "P+1 \t0.9992, 0.0005\n",
      "P+2 \t0.9984, 0.0009\n",
      "P+3 \t0.9972, 0.0014\n",
      "P+4 \t0.9958, 0.0019\n",
      "P+5 \t0.9945, 0.0023\n"
     ]
    }
   ],
   "source": [
    "mean_r2 = [np.mean(x[:, 5]) for x in d_cont]\n",
    "std_r2 = [np.std(x[:, 5]) for x in d_cont]\n",
    "\n",
    "for i, x in enumerate(zip(mean_r2, std_r2)):\n",
    "    print title_cont[i], '\\t' ,'%6.4f, %.4f' % tuple(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  (2) p and P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-1, R2: 0.9984, beta: 0.78\n",
      "P, R2: 0.9987, beta: 0.80\n",
      "P+1, R2: 0.9986, beta: 0.81\n",
      "P+2, R2: 0.9981, beta: 0.80\n",
      "P+3, R2: 0.9975, beta: 0.79\n",
      "P+4, R2: 0.9970, beta: 0.78\n",
      "P+5, R2: 0.9965, beta: 0.77\n"
     ]
    }
   ],
   "source": [
    "for i, title in enumerate(title_cont):\n",
    "    X_data = d_cont[i][:, 2]\n",
    "    Y_data = d_cont[i][:, 0]\n",
    "    to_fit = pd.DataFrame({'X':X_data,'Y':Y_data})\n",
    "    results = smf.ols('Y ~ X-1', data=to_fit).fit()\n",
    "    a = results.params['X']\n",
    "    r2 = results.rsquared\n",
    "    print('%s, R2: %.4f, beta: %.2f' %(title, r2, a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) q and Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-1, R2: 0.9984, beta: 5.35\n",
      "P, R2: 0.9990, beta: 5.20\n",
      "P+1, R2: 0.9991, beta: 5.07\n",
      "P+2, R2: 0.9993, beta: 4.93\n",
      "P+3, R2: 0.9992, beta: 4.81\n",
      "P+4, R2: 0.9992, beta: 4.71\n",
      "P+5, R2: 0.9993, beta: 4.64\n"
     ]
    }
   ],
   "source": [
    "for i, title in enumerate(title_cont):\n",
    "    X_data = d_cont[i][:, 1]\n",
    "    Y_data = d_cont[i][:, 3]\n",
    "    to_fit = pd.DataFrame({'X':X_data,'Y':Y_data})\n",
    "    results = smf.ols('Y ~ X-1', data=to_fit).fit()\n",
    "    a = results.params['X']\n",
    "    r2 = results.rsquared\n",
    "    print('%s, R2: %.4f, beta: %.2f' %(title, r2, a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (4) Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcu_distance(data, num_train=50):\n",
    "    '''\n",
    "    data: [[p, q, P, Q, M, r2]]\n",
    "    '''\n",
    "    df = pd.DataFrame(data, columns=['p', 'q', 'P', 'Q', 'M', 'r2'])\n",
    "    \n",
    "    # 随机生成训练集和测试集\n",
    "    num_tol = len(data)\n",
    "    idx_cont = np.arange(num_tol)\n",
    "    idx_train = np.random.choice(idx_cont, size=num_train, replace=False)  # for the training set\n",
    "    idx_test = np.array([i for i in idx_cont if i not in idx_train])  # the remaining is the test set\n",
    "    train_set = df.loc[idx_train, ['p', 'q', 'P', 'Q']]\n",
    "    test_set = df.loc[idx_test, ['p', 'q', 'P', 'Q']]\n",
    "    \n",
    "    # 预测 p\n",
    "    result_p = smf.ols('p ~ P-1', data=train_set).fit()\n",
    "    k_p = result_p.params['P']\n",
    "    r2_p = result_p.rsquared\n",
    "    train_set['pred_p'] = k_p * train_set['P']\n",
    "    test_set['pred_p'] = k_p * test_set['P']\n",
    "    \n",
    "    # 预测 q\n",
    "    result_q = smf.ols('q ~ Q-1', data=train_set).fit()\n",
    "    k_q = result_q.params['Q']\n",
    "    r2_q = result_q.rsquared\n",
    "    train_set['pred_q'] = k_q * train_set['Q']\n",
    "    test_set['pred_q'] = k_q * test_set['Q']\n",
    "    \n",
    "    # 测试集中预测点和实际点之前的距离\n",
    "    #dis_train = np.sqrt((train_set['p'] - train_set['pred_p']) ** 2  + (train_set['q'] - train_set['pred_q']) ** 2)\n",
    "    #dis_test = np.sqrt((test_set['p'] - test_set['pred_p']) ** 2 + (test_set['q'] - test_set['pred_q']) ** 2)\n",
    "    \n",
    "    dis_train = np.sqrt(np.square(train_set.p - train_set.pred_p) + np.square(train_set.q - train_set.pred_q))\n",
    "    dis_test = np.sqrt(np.square(test_set.p - test_set.pred_p) + np.square(test_set.q - test_set.pred_q))\n",
    "    \n",
    "    return dis_train, dis_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grid_distance(data, num_samp=10000):\n",
    "    df = pd.DataFrame(data, columns=['p', 'q', 'P', 'Q', 'M', 'r2'])\n",
    "    min_p, max_p = df.p.min(), df.p.max()\n",
    "    min_q, max_q = df.q.min(), df.q.max()\n",
    "    samp_p = (max_p - min_p) * np.random.random(num_samp) + min_p\n",
    "    samp_q = (max_q - min_q) * np.random.random(num_samp) + min_q\n",
    "    d_cont = []\n",
    "    for i in df.index:\n",
    "        d = np.mean(np.sqrt(np.square(samp_p - df.p[i]) + np.square(samp_q - df.q[i])))\n",
    "        d_cont.append(d)\n",
    "    \n",
    "    return np.mean(d_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res_dict = {}\n",
    "for i, title in enumerate(title_cont):\n",
    "    res_cont = []\n",
    "    data = d_cont[i]\n",
    "    for j in range(1000):\n",
    "        dis_train, dis_test = calcu_distance(data, num_train=9)      \n",
    "        res_cont.append([(np.mean(dis_train), np.std(dis_train)),\n",
    "                         (np.mean(dis_test), np.std(dis_test))])\n",
    "    res_dict[title] = res_cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-1 \t  Train: 0.00180 (0.000485) \t  Test: 0.00252 (0.000620)\n",
      "P \t  Train: 0.00235 (0.000362) \t  Test: 0.00219 (0.000950)\n",
      "P+1 \t  Train: 0.00199 (0.000582) \t  Test: 0.00088 (0.000309)\n",
      "P+2 \t  Train: 0.00163 (0.000124) \t  Test: 0.00058 (0.000237)\n",
      "P+3 \t  Train: 0.00149 (0.000355) \t  Test: 0.00108 (0.000143)\n",
      "P+4 \t  Train: 0.00198 (0.000401) \t  Test: 0.00135 (0.000317)\n",
      "P+5 \t  Train: 0.00153 (0.000837) \t  Test: 0.00146 (0.000553)\n"
     ]
    }
   ],
   "source": [
    "mean_dict1 = {}\n",
    "for i, title in enumerate(title_cont):\n",
    "    d = res_dict[title]\n",
    "    \n",
    "    mean_train = d[:][0][0]\n",
    "    std_train = d[:][0][1]\n",
    "    \n",
    "    mean_test = d[:][1][0]\n",
    "    std_test = d[:][1][1]\n",
    "    \n",
    "    mean_dict1[title] = [mean_train, mean_test]\n",
    "    \n",
    "    print  '%s' % title, '\\t',\n",
    "    print '  Train: %.5f (%.6f)' % (np.mean(mean_train), np.std(mean_train)), '\\t',\n",
    "    print ('  Test: %.5f (%.6f)' % (np.mean(mean_test), np.std(mean_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-1\t0.01769\tt-statistic = -24.448\t pvalue = 0.0260\n",
      "P\t0.01771\tt-statistic = -16.343\t pvalue = 0.0389\n",
      "P+1\t0.01774\tt-statistic = -54.573\t pvalue = 0.0117\n",
      "P+2\t0.01769\tt-statistic = -72.315\t pvalue = 0.0088\n",
      "P+3\t0.01772\tt-statistic = -116.598\t pvalue = 0.0055\n",
      "P+4\t0.01772\tt-statistic = -51.641\t pvalue = 0.0123\n",
      "P+5\t0.01770\tt-statistic = -29.375\t pvalue = 0.0217\n"
     ]
    }
   ],
   "source": [
    "for i, title in enumerate(title_cont):\n",
    "    data = d_cont[i]\n",
    "    samp = mean_dict1[title][1]\n",
    "    x = grid_distance(data)\n",
    "    print('%s' % title, end='\\t')\n",
    "    print('%.5f' % x, end='\\t')\n",
    "    print('t-statistic = %6.3f\\t pvalue = %6.4f' %  stats.ttest_1samp(samp, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
