{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H:\\Anaconda\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import time\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "u = \"C:/Users/XIAOYU/PycharmProjects/A-fast-method/auto_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcu_distance(data, num_train=50):\n",
    "    '''\n",
    "    data: [[p, q, P, Q, M, r2]]\n",
    "    '''\n",
    "    df = pd.DataFrame(data, columns=['p', 'q', 'P', 'Q', 'M', 'r2'])\n",
    "    \n",
    "    # 随机生成训练集和测试集\n",
    "    num_tol = len(data)\n",
    "    idx_cont = np.arange(num_tol)\n",
    "    idx_train = np.random.choice(idx_cont, size=num_train, replace=False)  # for the training set\n",
    "    idx_test = np.array([i for i in idx_cont if i not in idx_train])  # the remaining is the test set\n",
    "    train_set = df.loc[idx_train, ['p', 'q', 'P', 'Q']]\n",
    "    test_set = df.loc[idx_test, ['p', 'q', 'P', 'Q']]\n",
    "    \n",
    "    # 预测 p\n",
    "    result_p = smf.ols('p ~ P-1', data=train_set).fit()\n",
    "    k_p = result_p.params['P']\n",
    "    r2_p = result_p.rsquared\n",
    "    train_set['pred_p'] = k_p * train_set['P']\n",
    "    test_set['pred_p'] = k_p * test_set['P']\n",
    "    \n",
    "    # 预测 q\n",
    "    result_q = smf.ols('q ~ Q-1', data=train_set).fit()\n",
    "    k_q = result_q.params['Q']\n",
    "    r2_q = result_q.rsquared\n",
    "    train_set['pred_q'] = k_q * train_set['Q']\n",
    "    test_set['pred_q'] = k_q * test_set['Q']\n",
    "    \n",
    "    # 测试集中预测点和实际点之前的距离\n",
    "    #dis_train = np.sqrt((train_set['p'] - train_set['pred_p']) ** 2  + (train_set['q'] - train_set['pred_q']) ** 2)\n",
    "    #dis_test = np.sqrt((test_set['p'] - test_set['pred_p']) ** 2 + (test_set['q'] - test_set['pred_q']) ** 2)\n",
    "    \n",
    "    dis_train = np.sqrt(np.square(train_set.p - train_set.pred_p) + np.square(train_set.q - train_set.pred_q))\n",
    "    dis_test = np.sqrt(np.square(test_set.p - test_set.pred_p) + np.square(test_set.q - test_set.pred_q))\n",
    "    \n",
    "    return dis_train, dis_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grid_distance(data, num_samp=10000):\n",
    "    df = pd.DataFrame(data, columns=['p', 'q', 'P', 'Q', 'M', 'r2'])\n",
    "    min_p, max_p = df.p.min(), df.p.max()\n",
    "    min_q, max_q = df.q.min(), df.q.max()\n",
    "    samp_p = (max_p - min_p) * np.random.random(num_samp) + min_p\n",
    "    samp_q = (max_q - min_q) * np.random.random(num_samp) + min_q\n",
    "    d_cont = []\n",
    "    for i in df.index:\n",
    "        d = np.mean(np.sqrt(np.square(samp_p - df.p[i]) + np.square(samp_q - df.q[i])))\n",
    "        d_cont.append(d)\n",
    "    \n",
    "    return np.mean(d_cont)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$p=k_1\\cdot P$\n",
    "\n",
    "$q=k_2\\cdot Q$\n",
    "\n",
    "$D(\\mathrm{fit, predict}) = \\sqrt{(\\hat p - p)^2 + (\\hat q - q)^2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coeff_cont_gnm = np.load(u +\"estimate_gnm_random_graph(10000,30000).npy\")\n",
    "coeff_cont_ba =  np.load(u +\"estimate_barabasi_albert_graph(10000,3).npy\")\n",
    "coeff_cont_exp = np.load(u +\"estimate_exponential_graph(10000,3).npy\")\n",
    "coeff_cont_gua = np.load(u +\"estimate_gaussian_graph(10000,3).npy\")\n",
    "coeff_cont_log = np.load(u +\"estimate_lognormal_graph(10000,3).npy\")\n",
    "coeff_cont_full = np.load(u+\"estimate_complete_graph(10000).npy\")\n",
    "coeff_cont_ws0 =  np.load(u +\"estimate_watts_strogatz_graph(10000,6,0).npy\")\n",
    "coeff_cont_ws01 = np.load(u +\"estimate_watts_strogatz_graph(10000,6,0.1).npy\")\n",
    "coeff_cont_ws03 = np.load(u +\"estimate_watts_strogatz_graph(10000,6,0.3).npy\")\n",
    "coeff_cont_ws05 = np.load(u +\"estimate_watts_strogatz_graph(10000,6,0.5).npy\")\n",
    "coeff_cont_ws07 = np.load(u +\"estimate_watts_strogatz_graph(10000,6,0.7).npy\")\n",
    "coeff_cont_ws09 = np.load(u +\"estimate_watts_strogatz_graph(10000,6,0.9).npy\")\n",
    "coeff_cont_ws10 = np.load(u +\"estimate_watts_strogatz_graph(10000,6,1.0).npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_cont = [coeff_cont_log, coeff_cont_ba, coeff_cont_exp, coeff_cont_gua,\n",
    "          coeff_cont_gnm, coeff_cont_full,\n",
    "          coeff_cont_ws0, coeff_cont_ws01, coeff_cont_ws03,\n",
    "          coeff_cont_ws05, coeff_cont_ws07, coeff_cont_ws09, coeff_cont_ws10]\n",
    "\n",
    "title_cont = ['LOG','BA','EXP','GAU','ER', 'Full', 'WS-0','WS-0.1','WS-0.3','WS-0.5','WS-0.7','WS-0.9','WS-1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG \t 0.9959, 0.0042\n",
      "BA \t 0.9920, 0.0037\n",
      "EXP \t 0.9988, 0.0016\n",
      "GAU \t 0.9993, 0.0004\n",
      "ER \t 0.9992, 0.0005\n",
      "Full \t 0.9988, 0.0011\n",
      "WS-0 \t 0.9746, 0.0149\n",
      "WS-0.1 \t 0.9947, 0.0025\n",
      "WS-0.3 \t 0.9975, 0.0026\n",
      "WS-0.5 \t 0.9987, 0.0007\n",
      "WS-0.7 \t 0.9988, 0.0007\n",
      "WS-0.9 \t 0.9989, 0.0007\n",
      "WS-1 \t 0.9988, 0.0007\n"
     ]
    }
   ],
   "source": [
    "mean_r2 = [np.mean(x[:, 5]) for x in d_cont]\n",
    "std_r2 = [np.std(x[:, 5]) for x in d_cont]\n",
    "\n",
    "for i, x in enumerate(zip(mean_r2, std_r2)):\n",
    "    print(title_cont[i], '\\t' ,'%6.4f, %.4f' % tuple(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) P and p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_p = []\n",
    "for i, title in enumerate(title_cont):\n",
    "    X_data = d_cont[i][:, 2]\n",
    "    Y_data = d_cont[i][:, 0]\n",
    "    to_fit = pd.DataFrame({'X':X_data,'Y':Y_data})\n",
    "    results = smf.ols('Y ~ X-1', data=to_fit).fit()\n",
    "    a = results.params['X']\n",
    "    r2 = results.rsquared\n",
    "    print('%s || R2: %.4f, beta: %.2E' %(title, r2, a))\n",
    "    res_p.append([r2, a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) Q and q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_q = []\n",
    "for i, title in enumerate(title_cont):\n",
    "    X_data = d_cont[i][:, 3]\n",
    "    Y_data = d_cont[i][:, 1]\n",
    "    to_fit = pd.DataFrame({'X':X_data,'Y':Y_data})\n",
    "    results = smf.ols('Y ~ X-1', data=to_fit).fit()\n",
    "    a = results.params['X']\n",
    "    r2 = results.rsquared\n",
    "    print('%s || R2: %.4f, beta: %.2E' %(title, r2, a))\n",
    "    res_q.append([r2, a])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res_dict = {}\n",
    "for i, title in enumerate(title_cont):\n",
    "    res_cont = []\n",
    "    data = d_cont[i]\n",
    "    for j in range(1000):\n",
    "        dis_train, dis_test = calcu_distance(data, num_train=9)      \n",
    "        res_cont.append([(np.mean(dis_train), np.std(dis_train)),\n",
    "                         (np.mean(dis_test), np.std(dis_test))])\n",
    "    res_dict[title] = res_cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG\t  Train: 0.00202 (0.000243)\t  Test: 0.00234 (0.000001)\n",
      "BA\t  Train: 0.00669 (0.000329)\t  Test: 0.00589 (0.000619)\n",
      "EXP\t  Train: 0.00203 (0.000114)\t  Test: 0.00368 (0.000402)\n",
      "GAU\t  Train: 0.00098 (0.000228)\t  Test: 0.00095 (0.000404)\n",
      "ER\t  Train: 0.00096 (0.000195)\t  Test: 0.00209 (0.000374)\n",
      "Full\t  Train: 0.00160 (0.000006)\t  Test: 0.00070 (0.000168)\n",
      "WS-0\t  Train: 0.01617 (0.004418)\t  Test: 0.05181 (0.006433)\n",
      "WS-0.1\t  Train: 0.00599 (0.001937)\t  Test: 0.01252 (0.002486)\n",
      "WS-0.3\t  Train: 0.00366 (0.001248)\t  Test: 0.00557 (0.001159)\n",
      "WS-0.5\t  Train: 0.00235 (0.000652)\t  Test: 0.00235 (0.000375)\n",
      "WS-0.7\t  Train: 0.00284 (0.000608)\t  Test: 0.00287 (0.000998)\n",
      "WS-0.9\t  Train: 0.00195 (0.000429)\t  Test: 0.00162 (0.000270)\n",
      "WS-1\t  Train: 0.00287 (0.000024)\t  Test: 0.00236 (0.000800)\n"
     ]
    }
   ],
   "source": [
    "mean_dict1 = {}\n",
    "for i, title in enumerate(title_cont):\n",
    "    d = res_dict[title]\n",
    "    \n",
    "    mean_train = d[:][0][0]\n",
    "    std_train = d[:][0][1]\n",
    "    \n",
    "    mean_test = d[:][1][0]\n",
    "    std_test = d[:][1][1]\n",
    "    \n",
    "    mean_dict1[title] = [mean_train, mean_test]\n",
    "    \n",
    "    print ('%s' % title, end='\\t')\n",
    "    print ('  Train: %.5f (%.6f)' % (np.mean(mean_train), np.std(mean_train)), end='\\t')\n",
    "    print ('  Test: %.5f (%.6f)' % (np.mean(mean_test), np.std(mean_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (4) 和随机抽取点进行对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG\t0.01416\tt-statistic = -8324.093 pvalue = 0.0001\n",
      "BA\t0.01816\tt-statistic = -19.814 pvalue = 0.0321\n",
      "EXP\t0.01593\tt-statistic = -30.434 pvalue = 0.0209\n",
      "GAU\t0.01633\tt-statistic = -38.084 pvalue = 0.0167\n",
      "ER\t0.01772\tt-statistic = -41.787 pvalue = 0.0152\n",
      "Full\t0.01654\tt-statistic = -94.441 pvalue = 0.0067\n",
      "WS-0\t0.01968\tt-statistic =  4.993 pvalue = 0.1258\n",
      "WS-0.1\t0.01653\tt-statistic = -1.617 pvalue = 0.3526\n",
      "WS-0.3\t0.01609\tt-statistic = -9.074 pvalue = 0.0699\n",
      "WS-0.5\t0.03001\tt-statistic = -73.714 pvalue = 0.0086\n",
      "WS-0.7\t0.03001\tt-statistic = -27.194 pvalue = 0.0234\n",
      "WS-0.9\t0.03001\tt-statistic = -105.240 pvalue = 0.0060\n",
      "WS-1\t0.02999\tt-statistic = -34.527 pvalue = 0.0184\n"
     ]
    }
   ],
   "source": [
    "for i, title in enumerate(title_cont):\n",
    "    data = d_cont[i]\n",
    "    samp = mean_dict1[title][1]\n",
    "    x = grid_distance(data)\n",
    "    print('%s' % title, end='\\t')\n",
    "    print('%.5f' % x,  end='\\t')\n",
    "    print('t-statistic = %6.3f pvalue = %6.4f' %  stats.ttest_1samp(samp, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (5) 绘图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def voilin_plot(ax, d_cont, positions, title=False, xlabel=False, ylabel=False):\n",
    "    if xlabel:\n",
    "        ax.set_xlabel(xlabel, fontsize=15)\n",
    "    if ylabel:\n",
    "        ax.set_ylabel(ylabel, fontsize=15)\n",
    "    if title:\n",
    "        ax.set_title(title, fontsize=15)\n",
    "        \n",
    "    #ax.axhline(1, color='gray', ls='--', lw=1)\n",
    "    ax.set_ylim([0.92, 1.02])\n",
    "    #ax.yaxis.grid(True, linestyle='--', which='major', color='lightgrey',alpha=0.5)\n",
    "    ax.violinplot(d_cont, showmedians=False, showmeans=True, showextrema=False, widths=0.5, positions=positions)\n",
    "    for i, d in enumerate(d_cont):\n",
    "        textstr = '%.4f\\n(%.4f)' % (np.mean(d), np.std(d))\n",
    "        ax.text(i + 0.6, np.mean(d), textstr, fontsize=10, verticalalignment='center', color='k', alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def line_plot(ax, d_cont, positions, title=False, xlabel=False, ylabel=False):\n",
    "    if xlabel:\n",
    "        ax.set_xlabel(xlabel, fontsize=15)\n",
    "    if ylabel:\n",
    "        ax.set_ylabel(ylabel, fontsize=15)\n",
    "    if title:\n",
    "        ax.set_title(title, fontsize=15)\n",
    "    \n",
    "    r_cont = [d[0] for d in d_cont]\n",
    "    #ax.axhline(1, color='gray', ls='--', lw=1)\n",
    "    ax.plot(positions, r_cont, 'k--', lw=1, alpha=0.4)\n",
    "    ax.scatter(positions, r_cont, marker='o', s=60, alpha=0.8, lw=1)\n",
    "        \n",
    "    for i, d in enumerate(d_cont):\n",
    "        text = '%.4f\\n{%.1e}'% tuple(d)\n",
    "        ax.text(i + 0.6, d[0], text, fontsize=10, verticalalignment='center', color='k', alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "positions = np.arange(1, len(title_cont) + 1)\n",
    "r_cont1 = [v[:,-1] for v in d_cont]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = pl.figure(figsize=(12, 10))\n",
    "\n",
    "ax1 = fig.add_subplot(3, 1, 1)\n",
    "voilin_plot(ax1, r_cont1, positions, title='(a) Results for the DE', ylabel='$R^2$')\n",
    "ax1.set_xticklabels([])\n",
    "\n",
    "ax2 = fig.add_subplot(3, 1, 2)\n",
    "line_plot(ax2, res_p, positions, title='(b) Results for Linear model 1', ylabel=r'$R^2$ and $\\beta$')\n",
    "ax3.set_ylim([0.88, 1.02])\n",
    "ax2.set_xticklabels([])\n",
    "\n",
    "ax3 = fig.add_subplot(3, 1, 3)\n",
    "line_plot(ax3, res_q, positions, title='(c) Results for Linear model 2', ylabel=r'$R^2$ and $\\beta$')\n",
    "ax3.set_ylim([0.88, 1.02])\n",
    "\n",
    "pl.setp(ax1, xticks=positions, xticklabels=title_cont)\n",
    "pl.setp(ax2, xticks=positions, xticklabels=title_cont)\n",
    "pl.setp(ax3, xticks=positions, xticklabels=title_cont)\n",
    "pl.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.  average degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coeff_cont_gnm_3 = np.load(u + \"estimate_gnm_random_graph(10000,30000).npy\")\n",
    "coeff_cont_gnm_4 = np.load(u + \"estimate_gnm_random_graph(10000,40000).npy\")\n",
    "coeff_cont_gnm_5 = np.load(u + \"estimate_gnm_random_graph(10000,50000).npy\")\n",
    "coeff_cont_gnm_6 = np.load(u + \"estimate_gnm_random_graph(10000,60000).npy\")\n",
    "coeff_cont_gnm_7 = np.load(u + \"estimate_gnm_random_graph(10000,70000).npy\")\n",
    "coeff_cont_gnm_8 = np.load(u + \"estimate_gnm_random_graph(10000,80000).npy\")\n",
    "coeff_cont_gnm_9 = np.load(u + \"estimate_gnm_random_graph(10000,90000).npy\")\n",
    "coeff_cont_gnm_10 = np.load(u + \"estimate_gnm_random_graph(10000,100000).npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_cont2 = [coeff_cont_gnm_3,coeff_cont_gnm_4,coeff_cont_gnm_5,coeff_cont_gnm_6,\n",
    "                     coeff_cont_gnm_7,coeff_cont_gnm_8,coeff_cont_gnm_9,coeff_cont_gnm_10]\n",
    "title_cont2 = ['gnm3', 'gnm4', 'gnm5', 'gnm6', 'gnm7', 'gnm8', 'gnm9', 'gnm10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gnm3 \t 0.9992, 0.0005\n",
      "gnm4 \t 0.9992, 0.0005\n",
      "gnm5 \t 0.9993, 0.0004\n",
      "gnm6 \t 0.9994, 0.0004\n",
      "gnm7 \t 0.9994, 0.0004\n",
      "gnm8 \t 0.9995, 0.0004\n",
      "gnm9 \t 0.9994, 0.0004\n",
      "gnm10 \t 0.9995, 0.0004\n"
     ]
    }
   ],
   "source": [
    "mean_r2 = [np.mean(x[:, 5]) for x in d_cont2]\n",
    "std_r2 = [np.std(x[:, 5]) for x in d_cont2]\n",
    "\n",
    "for i, x in enumerate(zip(mean_r2, std_r2)):\n",
    "    print(title_cont2[i], '\\t' ,'%6.4f, %.4f' % tuple(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) P and p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, title in enumerate(title_cont2):\n",
    "    X_data = d_cont2[i][:, 2]\n",
    "    Y_data = d_cont2[i][:, 0]\n",
    "    to_fit = pd.DataFrame({'X':X_data,'Y':Y_data})\n",
    "    results = smf.ols('Y ~ X-1', data=to_fit).fit()\n",
    "    a = results.params['X']\n",
    "    r2 = results.rsquared\n",
    "    print('%s \\n R2: %.4f, beta: %.2f' %(title, r2, a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) Q and q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, title in enumerate(title_cont2):\n",
    "    X_data = d_cont2[i][:, 3]\n",
    "    Y_data = d_cont2[i][:, 1]\n",
    "    to_fit = pd.DataFrame({'X':X_data,'Y':Y_data})\n",
    "    results = smf.ols('Y ~ X-1', data=to_fit).fit()\n",
    "    a = results.params['X']\n",
    "    r2 = results.rsquared\n",
    "    print('%s \\n R2: %.4f, beta: %.2f' %(title, r2, a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 82.37s \n"
     ]
    }
   ],
   "source": [
    "res_dict2 = {}\n",
    "t1= time.clock()\n",
    "for i, title in enumerate(title_cont2):\n",
    "    res_cont = []\n",
    "    data = d_cont2[i]\n",
    "    for j in range(1000):\n",
    "        dis_train, dis_test = calcu_distance(data, num_train=9)      \n",
    "        res_cont.append([(np.mean(dis_train), np.std(dis_train)),\n",
    "                         (np.mean(dis_test), np.std(dis_test))])\n",
    "        \n",
    "    res_dict2[title] = res_cont\n",
    "print('Time elapsed: %.2fs ' % (time.clock() - t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gnm3 \t\n",
      "  Train: 0.00134 (0.000283)\t  Test: 0.00081 (0.000180)\n",
      "gnm4 \t\n",
      "  Train: 0.00082 (0.000198)\t  Test: 0.00085 (0.000326)\n",
      "gnm5 \t\n",
      "  Train: 0.00064 (0.000164)\t  Test: 0.00099 (0.000318)\n",
      "gnm6 \t\n",
      "  Train: 0.00046 (0.000147)\t  Test: 0.00052 (0.000060)\n",
      "gnm7 \t\n",
      "  Train: 0.00114 (0.000254)\t  Test: 0.00071 (0.000172)\n",
      "gnm8 \t\n",
      "  Train: 0.00068 (0.000148)\t  Test: 0.00060 (0.000298)\n",
      "gnm9 \t\n",
      "  Train: 0.00070 (0.000167)\t  Test: 0.00049 (0.000246)\n",
      "gnm10 \t\n",
      "  Train: 0.00038 (0.000128)\t  Test: 0.00045 (0.000069)\n"
     ]
    }
   ],
   "source": [
    "mean_dict2 = {}\n",
    "for i, title in enumerate(title_cont2):\n",
    "    d = res_dict2[title]\n",
    "    mean_train = d[:][0][0]\n",
    "    std_train = d[:][0][1]\n",
    "    \n",
    "    mean_test = d[:][1][0]\n",
    "    std_test = d[:][1][1]\n",
    "    \n",
    "    mean_dict2[title] = [mean_train, mean_test]\n",
    "    \n",
    "    print('%s' % title, end='\\t')\n",
    "    print('  Train: %.5f (%.6f)' % (np.mean(mean_train), np.std(mean_train)), end='\\t')\n",
    "    print('  Test: %.5f (%.6f)' % (np.mean(mean_test), np.std(mean_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (4) 和随机抽取点对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gnm3\t0.01763\tt-statistic = -93.403 pvalue = 0.0068\n",
      "gnm4\t0.01487\tt-statistic = -43.041 pvalue = 0.0148\n",
      "gnm5\t0.01331\tt-statistic = -38.698 pvalue = 0.0164\n",
      "gnm6\t0.01246\tt-statistic = -199.657 pvalue = 0.0032\n",
      "gnm7\t0.01284\tt-statistic = -70.543 pvalue = 0.0090\n",
      "gnm8\t0.01231\tt-statistic = -39.288 pvalue = 0.0162\n",
      "gnm9\t0.01089\tt-statistic = -42.367 pvalue = 0.0150\n",
      "gnm10\t0.01130\tt-statistic = -157.190 pvalue = 0.0040\n"
     ]
    }
   ],
   "source": [
    "for i, title in enumerate(title_cont2):\n",
    "    data = d_cont2[i]    \n",
    "    samp = mean_dict2[title][1]\n",
    "    x = grid_distance(data)\n",
    "    print('%s' % title, end='\\t')\n",
    "    print('%.5f' % x,  end='\\t')\n",
    "    print('t-statistic = %6.3f pvalue = %6.4f' %  stats.ttest_1samp(samp, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. decision rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coeff_cont_gnm01 = np.load(u +\"estimate_gnm_random_graph(10000,30000),0.1.npy\")\n",
    "coeff_cont_gnm03 = np.load(u +\"estimate_gnm_random_graph(10000,30000),0.3.npy\")\n",
    "coeff_cont_gnm05 = np.load(u +\"estimate_gnm_random_graph(10000,30000),0.5.npy\")\n",
    "coeff_cont_gnm07 = np.load(u +\"estimate_gnm_random_graph(10000,30000),0.7.npy\")\n",
    "coeff_cont_gnm09 = np.load(u +\"estimate_gnm_random_graph(10000,30000),0.9.npy\")\n",
    "coeff_cont_gnm10 = np.load(u +\"estimate_gnm_random_graph(10000,30000),1.0.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_cont3 = [coeff_cont_gnm01,coeff_cont_gnm03,coeff_cont_gnm05,coeff_cont_gnm07,coeff_cont_gnm09,coeff_cont_gnm10]\n",
    "title_cont3 = ['alpha0.1', 'alpha0.3', 'alpha0.5', 'alpha0.7', 'alpha0.9', 'alpha1.0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha0.1 \t 0.9991, 0.0005\n",
      "alpha0.3 \t 0.9991, 0.0005\n",
      "alpha0.5 \t 0.9987, 0.0013\n",
      "alpha0.7 \t 0.9989, 0.0007\n",
      "alpha0.9 \t 0.9987, 0.0012\n",
      "alpha1.0 \t 0.9989, 0.0007\n"
     ]
    }
   ],
   "source": [
    "mean_r2 = [np.mean(x[:, 5]) for x in d_cont3]\n",
    "std_r2 = [np.std(x[:, 5]) for x in d_cont3]\n",
    "\n",
    "for i, x in enumerate(zip(mean_r2, std_r2)):\n",
    "    print(title_cont3[i], '\\t' ,'%6.4f, %.4f' % tuple(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) P and p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, title in enumerate(title_cont3):\n",
    "    X_data = d_cont3[i][:, 2]\n",
    "    Y_data = d_cont3[i][:, 0]\n",
    "    to_fit = pd.DataFrame({'X':X_data,'Y':Y_data})\n",
    "    results = smf.ols('Y ~ X-1', data=to_fit).fit()\n",
    "    a = results.params['X']\n",
    "    r2 = results.rsquared\n",
    "    print('%s \\n R2: %.4f, beta: %.2f' %(title, r2, a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) Q and q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, title in enumerate(title_cont3):\n",
    "    X_data = d_cont3[i][:, 3]\n",
    "    Y_data = d_cont3[i][:, 1]\n",
    "    to_fit = pd.DataFrame({'X':X_data,'Y':Y_data})\n",
    "    results = smf.ols('Y ~ X-1', data=to_fit).fit()\n",
    "    a = results.params['X']\n",
    "    r2 = results.rsquared\n",
    "    print('%s \\n R2: %.4f, beta: %.2f' %(title, r2, a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res_dict3 = {}\n",
    "for i, title in enumerate(title_cont3):\n",
    "    res_cont = []\n",
    "    data = d_cont3[i]\n",
    "    for j in range(1000):\n",
    "        dis_train, dis_test = calcu_distance(data, num_train=9)      \n",
    "        res_cont.append([(np.mean(dis_train), np.std(dis_train)),\n",
    "                         (np.mean(dis_test), np.std(dis_test))])\n",
    "    res_dict3[title] = res_cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha0.1\t  Train: 0.00286 (0.000218)\t  Test: 0.00282 (0.001016)\n",
      "alpha0.3\t  Train: 0.00215 (0.000361)\t  Test: 0.00272 (0.000733)\n",
      "alpha0.5\t  Train: 0.00363 (0.001033)\t  Test: 0.00879 (0.000993)\n",
      "alpha0.7\t  Train: 0.01010 (0.001621)\t  Test: 0.00541 (0.000340)\n",
      "alpha0.9\t  Train: 0.01027 (0.001233)\t  Test: 0.03744 (0.005074)\n",
      "alpha1.0\t  Train: 0.01286 (0.002809)\t  Test: 0.01669 (0.007420)\n"
     ]
    }
   ],
   "source": [
    "mean_dict3 = {}\n",
    "for i, title in enumerate(title_cont3):\n",
    "    d = res_dict3[title]\n",
    "    mean_train = d[:][0][0]\n",
    "    std_train = d[:][0][1]\n",
    "    \n",
    "    mean_test = d[:][1][0]\n",
    "    std_test = d[:][1][1]\n",
    "    \n",
    "    mean_dict3[title] = [mean_train, mean_test]\n",
    "    \n",
    "    print('%s' % title, end='\\t')\n",
    "    print('  Train: %.5f (%.6f)' % (np.mean(mean_train), np.std(mean_train)), end='\\t')\n",
    "    print('  Test: %.5f (%.6f)' % (np.mean(mean_test), np.std(mean_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha0.1\t0.01821\tt-statistic = -15.134 pvalue = 0.0420\n",
      "alpha0.3\t0.02385\tt-statistic = -28.827 pvalue = 0.0221\n",
      "alpha0.5\t0.03225\tt-statistic = -23.640 pvalue = 0.0269\n",
      "alpha0.7\t0.04455\tt-statistic = -115.115 pvalue = 0.0055\n",
      "alpha0.9\t0.06232\tt-statistic = -4.904 pvalue = 0.1281\n",
      "alpha1.0\t0.07416\tt-statistic = -7.747 pvalue = 0.0817\n"
     ]
    }
   ],
   "source": [
    "for i, title in enumerate(title_cont3):\n",
    "    data = d_cont3[i]\n",
    "    samp = mean_dict3[title][1]\n",
    "    x = grid_distance(data)\n",
    "    print('%s' % title, end='\\t')\n",
    "    print('%.5f' % x,  end='\\t')\n",
    "    print('t-statistic = %6.3f pvalue = %6.4f' %  stats.ttest_1samp(samp, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. individual heterogeneity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coeff_cont_sgima01 = np.load(u +\"estimate_sigma-0.1.npy\")\n",
    "coeff_cont_sgima02 = np.load(u +\"estimate_sigma-0.2.npy\")\n",
    "coeff_cont_sgima04 = np.load(u +\"estimate_sigma-0.4.npy\")\n",
    "coeff_cont_sgima06 = np.load(u +\"estimate_sigma-0.6.npy\")\n",
    "coeff_cont_sgima08 = np.load(u +\"estimate_sigma-0.8.npy\")\n",
    "coeff_cont_sgima10 = np.load(u +\"estimate_sigma-1.0.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_cont4 = [coeff_cont_sgima01,coeff_cont_sgima02,coeff_cont_sgima04,\n",
    "           coeff_cont_sgima06,coeff_cont_sgima08,coeff_cont_sgima10]\n",
    "title_cont4 = ['sigma0.1', 'sigma0.2', 'sigma0.4', 'sigma0.6', 'sigma0.8', 'sigma1.0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma0.1 \t 0.9991, 0.0005\n",
      "sigma0.2 \t 0.9992, 0.0005\n",
      "sigma0.4 \t 0.9989, 0.0006\n",
      "sigma0.6 \t 0.9987, 0.0007\n",
      "sigma0.8 \t 0.9985, 0.0009\n",
      "sigma1.0 \t 0.9985, 0.0010\n"
     ]
    }
   ],
   "source": [
    "mean_r2 = [np.mean(x[:, 5]) for x in d_cont4]\n",
    "std_r2 = [np.std(x[:, 5]) for x in d_cont4]\n",
    "\n",
    "for i, x in enumerate(zip(mean_r2, std_r2)):\n",
    "    print(title_cont4[i], '\\t' ,'%6.4f, %.4f' % tuple(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) P and p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, title in enumerate(title_cont4):\n",
    "    X_data = d_cont4[i][:, 2]\n",
    "    Y_data = d_cont4[i][:, 0]\n",
    "    to_fit = pd.DataFrame({'X':X_data,'Y':Y_data})\n",
    "    results = smf.ols('Y ~ X-1', data=to_fit).fit()\n",
    "    a = results.params['X']\n",
    "    r2 = results.rsquared\n",
    "    print('%s \\n R2: %.4f, beta: %.2f' %(title, r2, a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) Q and q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, title in enumerate(title_cont4):\n",
    "    X_data = d_cont4[i][:, 3]\n",
    "    Y_data = d_cont4[i][:, 1]\n",
    "    to_fit = pd.DataFrame({'X':X_data,'Y':Y_data})\n",
    "    results = smf.ols('Y ~ X-1', data=to_fit).fit()\n",
    "    a = results.params['X']\n",
    "    r2 = results.rsquared\n",
    "    print('%s \\n R2: %.4f, beta: %.2f' %(title, r2, a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res_dict4 = {}\n",
    "for i, title in enumerate(title_cont4):\n",
    "    res_cont = []\n",
    "    data = d_cont4[i]\n",
    "    for j in range(1000):\n",
    "        dis_train, dis_test = calcu_distance(data, num_train=9)      \n",
    "        res_cont.append([(np.mean(dis_train), np.std(dis_train)),\n",
    "                         (np.mean(dis_test), np.std(dis_test))])\n",
    "        \n",
    "    res_dict4[title] = res_cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma0.1\t  Train: 0.00143 (0.000286)\t  Test: 0.00143 (0.000183)\n",
      "sigma0.2\t  Train: 0.00181 (0.000430)\t  Test: 0.00162 (0.000258)\n",
      "sigma0.4\t  Train: 0.00178 (0.000598)\t  Test: 0.00230 (0.000510)\n",
      "sigma0.6\t  Train: 0.00170 (0.000652)\t  Test: 0.00521 (0.000292)\n",
      "sigma0.8\t  Train: 0.00106 (0.000324)\t  Test: 0.00410 (0.000767)\n",
      "sigma1.0\t  Train: 0.00185 (0.000210)\t  Test: 0.00171 (0.000284)\n"
     ]
    }
   ],
   "source": [
    "mean_dict4 = {}\n",
    "for i, title in enumerate(title_cont4):\n",
    "    d = res_dict4[title]\n",
    "    mean_train = d[:][0][0]\n",
    "    std_train = d[:][0][1]\n",
    "    \n",
    "    mean_test = d[:][1][0]\n",
    "    std_test = d[:][1][1]\n",
    "    \n",
    "    mean_dict4[title] = [mean_train, mean_test]\n",
    "    \n",
    "    print('%s' % title, end='\\t')\n",
    "    print('  Train: %.5f (%.6f)' % (np.mean(mean_train), np.std(mean_train)), end='\\t')\n",
    "    print('  Test: %.5f (%.6f)' % (np.mean(mean_test), np.std(mean_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma0.1\t0.02131\tt-statistic = -108.576 pvalue = 0.0059\n",
      "sigma0.2\t0.02130\tt-statistic = -76.204 pvalue = 0.0084\n",
      "sigma0.4\t0.02087\tt-statistic = -36.404 pvalue = 0.0175\n",
      "sigma0.6\t0.02080\tt-statistic = -53.304 pvalue = 0.0119\n",
      "sigma0.8\t0.01815\tt-statistic = -18.318 pvalue = 0.0347\n",
      "sigma1.0\t0.01817\tt-statistic = -57.847 pvalue = 0.0110\n"
     ]
    }
   ],
   "source": [
    "for i, title in enumerate(title_cont4):\n",
    "    data = d_cont4[i]\n",
    "    samp = mean_dict4[title][1]\n",
    "    x = grid_distance(data)\n",
    "    print('%s' % title, end='\\t')\n",
    "    print('%.5f' % x,  end='\\t')\n",
    "    print('t-statistic = %6.3f pvalue = %6.4f' %  stats.ttest_1samp(samp, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
