{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H:\\Anaconda\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import time\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "u = \"C:/Users/XIAOYU/PycharmProjects/A-fast-method/auto_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcu_distance(data, num_train=50):\n",
    "    '''\n",
    "    data: [[p, q, P, Q, M, r2]]\n",
    "    '''\n",
    "    df = pd.DataFrame(data, columns=['p', 'q', 'P', 'Q', 'M', 'r2'])\n",
    "    \n",
    "    # 随机生成训练集和测试集\n",
    "    num_tol = len(data)\n",
    "    idx_cont = np.arange(num_tol)\n",
    "    idx_train = np.random.choice(idx_cont, size=num_train, replace=False)  # the index for the training set\n",
    "    idx_test = np.array([i for i in idx_cont if i not in idx_train])  # the remaining is the test set\n",
    "    train_set = df.loc[idx_train, ['p', 'q', 'P', 'Q']]\n",
    "    test_set = df.loc[idx_test, ['p', 'q', 'P', 'Q']]\n",
    "    \n",
    "    # 预测 p\n",
    "    result_p = smf.ols('p ~ P + Q -1', data=train_set).fit()\n",
    "    k_p_p = result_p.params['P']\n",
    "    k_p_q = result_p.params['Q']\n",
    "    train_set['pred_p'] = k_p_p * train_set['P'] + k_p_q * train_set['Q']\n",
    "    test_set['pred_p'] = k_p_p * test_set['P'] + k_p_q * test_set['Q']\n",
    "    \n",
    "    # 预测 q\n",
    "    result_q = smf.ols('q ~ P + Q -1', data=train_set).fit()\n",
    "    k_q_p = result_q.params['P']\n",
    "    k_q_q = result_q.params['Q']\n",
    "    \n",
    "    train_set['pred_q'] = k_q_p * train_set['P'] + k_q_q * train_set['Q']\n",
    "    test_set['pred_q'] = k_q_p * test_set['P'] + k_q_q * test_set['Q']\n",
    "    \n",
    "    # 预测点和实际点之间的距离    \n",
    "    dis_train = np.sqrt(np.square(train_set.p - train_set.pred_p) + np.square(train_set.q - train_set.pred_q))\n",
    "    dis_test = np.sqrt(np.square(test_set.p - test_set.pred_p) + np.square(test_set.q - test_set.pred_q))\n",
    "    \n",
    "    return dis_train, dis_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grid_distance(data, num_samp=10000):\n",
    "    df = pd.DataFrame(data, columns=['p', 'q', 'P', 'Q', 'M', 'r2'])\n",
    "    min_p, max_p = df.p.min(), df.p.max()\n",
    "    min_q, max_q = df.q.min(), df.q.max()\n",
    "    samp_p = (max_p - min_p) * np.random.random(num_samp) + min_p\n",
    "    samp_q = (max_q - min_q) * np.random.random(num_samp) + min_q\n",
    "    d_cont = []\n",
    "    for i in df.index:\n",
    "        d = np.mean(np.sqrt(np.square(samp_p - df.p[i]) + np.square(samp_q - df.q[i])))\n",
    "        d_cont.append(d)\n",
    "    \n",
    "    return np.mean(d_cont)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$p=k_1\\cdot P$\n",
    "\n",
    "$q=k_2\\cdot Q$\n",
    "\n",
    "$D(\\mathrm{fit, predict}) = \\sqrt{(\\hat p - p)^2 + (\\hat q - q)^2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coeff_cont_gnm = np.load(u +\"estimate_gnm_random_graph(10000,30000).npy\")\n",
    "coeff_cont_ba =  np.load(u +\"estimate_barabasi_albert_graph(10000,3).npy\")\n",
    "coeff_cont_exp = np.load(u +\"estimate_exponential_graph(10000,3).npy\")\n",
    "coeff_cont_gua = np.load(u +\"estimate_gaussian_graph(10000,3).npy\")\n",
    "coeff_cont_log = np.load(u +\"estimate_lognormal_graph(10000,3).npy\")\n",
    "coeff_cont_full = np.load(u+\"estimate_complete_graph(10000).npy\")\n",
    "coeff_cont_ws0 =  np.load(u +\"estimate_watts_strogatz_graph(10000,6,0).npy\")\n",
    "coeff_cont_ws01 = np.load(u +\"estimate_watts_strogatz_graph(10000,6,0.1).npy\")\n",
    "coeff_cont_ws03 = np.load(u +\"estimate_watts_strogatz_graph(10000,6,0.3).npy\")\n",
    "coeff_cont_ws05 = np.load(u +\"estimate_watts_strogatz_graph(10000,6,0.5).npy\")\n",
    "coeff_cont_ws07 = np.load(u +\"estimate_watts_strogatz_graph(10000,6,0.7).npy\")\n",
    "coeff_cont_ws09 = np.load(u +\"estimate_watts_strogatz_graph(10000,6,0.9).npy\")\n",
    "coeff_cont_ws10 = np.load(u +\"estimate_watts_strogatz_graph(10000,6,1.0).npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_cont = [coeff_cont_log, coeff_cont_ba, coeff_cont_exp, coeff_cont_gua,\n",
    "          coeff_cont_gnm, coeff_cont_full,\n",
    "          coeff_cont_ws0, coeff_cont_ws01, coeff_cont_ws03,\n",
    "          coeff_cont_ws05, coeff_cont_ws07, coeff_cont_ws09, coeff_cont_ws10]\n",
    "\n",
    "title_cont = ['LOG','BA','EXP','GAU','ER', 'Full', 'WS-0','WS-0.1','WS-0.3','WS-0.5','WS-0.7','WS-0.9','WS-1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG \t 0.9959, 0.0042\n",
      "BA \t 0.9920, 0.0037\n",
      "EXP \t 0.9988, 0.0016\n",
      "GAU \t 0.9993, 0.0004\n",
      "ER \t 0.9992, 0.0005\n",
      "Full \t 0.9988, 0.0011\n",
      "WS-0 \t 0.9746, 0.0149\n",
      "WS-0.1 \t 0.9947, 0.0025\n",
      "WS-0.3 \t 0.9975, 0.0026\n",
      "WS-0.5 \t 0.9987, 0.0007\n",
      "WS-0.7 \t 0.9988, 0.0007\n",
      "WS-0.9 \t 0.9989, 0.0007\n",
      "WS-1 \t 0.9988, 0.0007\n"
     ]
    }
   ],
   "source": [
    "mean_r2 = [np.mean(x[:, 5]) for x in d_cont]\n",
    "std_r2 = [np.std(x[:, 5]) for x in d_cont]\n",
    "\n",
    "for i, x in enumerate(zip(mean_r2, std_r2)):\n",
    "    print(title_cont[i], '\\t' ,'%6.4f, %.4f' % tuple(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) P and p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res_p = []\n",
    "for i, title in enumerate(title_cont):\n",
    "    X_data = d_cont[i][:, 2]\n",
    "    Y_data = d_cont[i][:, 0]\n",
    "    to_fit = pd.DataFrame({'X':X_data,'Y':Y_data})\n",
    "    results = smf.ols('Y ~ X-1', data=to_fit).fit()\n",
    "    a = results.params['X']\n",
    "    r2 = results.rsquared\n",
    "    print('%s || R2: %.4f, beta: %.2E' %(title, r2, a))\n",
    "    res_p.append([r2, a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) Q and q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res_q = []\n",
    "for i, title in enumerate(title_cont):\n",
    "    X_data = d_cont[i][:, 3]\n",
    "    Y_data = d_cont[i][:, 1]\n",
    "    to_fit = pd.DataFrame({'X':X_data,'Y':Y_data})\n",
    "    results = smf.ols('Y ~ X-1', data=to_fit).fit()\n",
    "    a = results.params['X']\n",
    "    r2 = results.rsquared\n",
    "    print('%s || R2: %.4f, beta: %.2E' %(title, r2, a))\n",
    "    res_q.append([r2, a])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res_dict = {}\n",
    "for i, title in enumerate(title_cont):\n",
    "    res_cont = []\n",
    "    data = d_cont[i]\n",
    "    for j in range(1000):\n",
    "        dis_train, dis_test = calcu_distance(data, num_train=9)      \n",
    "        res_cont.append([(np.mean(dis_train), np.std(dis_train)),\n",
    "                         (np.mean(dis_test), np.std(dis_test))])\n",
    "    res_dict[title] = res_cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG\t  Train: 0.00084 (0.000269)\t  Test: 0.00267 (0.000117)\n",
      "BA\t  Train: 0.00230 (0.000317)\t  Test: 0.00102 (0.000257)\n",
      "EXP\t  Train: 0.00077 (0.000285)\t  Test: 0.00086 (0.000221)\n",
      "GAU\t  Train: 0.00089 (0.000172)\t  Test: 0.00066 (0.000179)\n",
      "ER\t  Train: 0.00071 (0.000300)\t  Test: 0.00094 (0.000195)\n",
      "Full\t  Train: 0.00110 (0.000197)\t  Test: 0.00094 (0.000161)\n",
      "WS-0\t  Train: 0.01280 (0.001728)\t  Test: 0.02730 (0.004131)\n",
      "WS-0.1\t  Train: 0.00376 (0.001026)\t  Test: 0.00249 (0.000754)\n",
      "WS-0.3\t  Train: 0.00367 (0.000107)\t  Test: 0.00139 (0.000477)\n",
      "WS-0.5\t  Train: 0.00220 (0.000329)\t  Test: 0.00194 (0.000506)\n",
      "WS-0.7\t  Train: 0.00199 (0.000220)\t  Test: 0.00242 (0.000382)\n",
      "WS-0.9\t  Train: 0.00214 (0.000667)\t  Test: 0.00139 (0.000536)\n",
      "WS-1\t  Train: 0.00192 (0.000745)\t  Test: 0.00139 (0.000123)\n"
     ]
    }
   ],
   "source": [
    "mean_dict1 = {}\n",
    "for i, title in enumerate(title_cont):\n",
    "    d = res_dict[title]\n",
    "    \n",
    "    mean_train = d[:][0][0]\n",
    "    std_train = d[:][0][1]\n",
    "    \n",
    "    mean_test = d[:][1][0]\n",
    "    std_test = d[:][1][1]\n",
    "    \n",
    "    mean_dict1[title] = [mean_train, mean_test]\n",
    "    \n",
    "    print ('%s' % title, end='\\t')\n",
    "    print ('  Train: %.5f (%.6f)' % (np.mean(mean_train), np.std(mean_train)), end='\\t')\n",
    "    print ('  Test: %.5f (%.6f)' % (np.mean(mean_test), np.std(mean_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (4) 和随机抽取点进行对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG\t0.01419\tt-statistic = -98.405\t pvalue = 0.0065\n",
      "BA\t0.01816\tt-statistic = -66.791\t pvalue = 0.0095\n",
      "EXP\t0.01596\tt-statistic = -68.213\t pvalue = 0.0093\n",
      "GAU\t0.01621\tt-statistic = -87.005\t pvalue = 0.0073\n",
      "ER\t0.01769\tt-statistic = -86.037\t pvalue = 0.0074\n",
      "Full\t0.01656\tt-statistic = -96.758\t pvalue = 0.0066\n",
      "WS-0\t0.01971\tt-statistic =  1.836\t pvalue = 0.3175\n",
      "WS-0.1\t0.01648\tt-statistic = -18.548\t pvalue = 0.0343\n",
      "WS-0.3\t0.01615\tt-statistic = -30.911\t pvalue = 0.0206\n",
      "WS-0.5\t0.02996\tt-statistic = -55.399\t pvalue = 0.0115\n",
      "WS-0.7\t0.03002\tt-statistic = -72.306\t pvalue = 0.0088\n",
      "WS-0.9\t0.03010\tt-statistic = -53.515\t pvalue = 0.0119\n",
      "WS-1\t0.02996\tt-statistic = -231.367\t pvalue = 0.0028\n"
     ]
    }
   ],
   "source": [
    "for i, title in enumerate(title_cont):\n",
    "    data = d_cont[i]\n",
    "    samp = mean_dict1[title][1]\n",
    "    x = grid_distance(data)\n",
    "    print('%s' % title, end='\\t')\n",
    "    print('%.5f' % x,  end='\\t')\n",
    "    print('t-statistic = %6.3f\\t pvalue = %6.4f' %  stats.ttest_1samp(samp, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.  average degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coeff_cont_gnm_3 = np.load(u + \"estimate_gnm_random_graph(10000,30000).npy\")\n",
    "coeff_cont_gnm_4 = np.load(u + \"estimate_gnm_random_graph(10000,40000).npy\")\n",
    "coeff_cont_gnm_5 = np.load(u + \"estimate_gnm_random_graph(10000,50000).npy\")\n",
    "coeff_cont_gnm_6 = np.load(u + \"estimate_gnm_random_graph(10000,60000).npy\")\n",
    "coeff_cont_gnm_7 = np.load(u + \"estimate_gnm_random_graph(10000,70000).npy\")\n",
    "coeff_cont_gnm_8 = np.load(u + \"estimate_gnm_random_graph(10000,80000).npy\")\n",
    "coeff_cont_gnm_9 = np.load(u + \"estimate_gnm_random_graph(10000,90000).npy\")\n",
    "coeff_cont_gnm_10 = np.load(u + \"estimate_gnm_random_graph(10000,100000).npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_cont2 = [coeff_cont_gnm_3,coeff_cont_gnm_4,coeff_cont_gnm_5,coeff_cont_gnm_6,\n",
    "                     coeff_cont_gnm_7,coeff_cont_gnm_8,coeff_cont_gnm_9,coeff_cont_gnm_10]\n",
    "title_cont2 = ['gnm3', 'gnm4', 'gnm5', 'gnm6', 'gnm7', 'gnm8', 'gnm9', 'gnm10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gnm3 \t 0.9992, 0.0005\n",
      "gnm4 \t 0.9992, 0.0005\n",
      "gnm5 \t 0.9993, 0.0004\n",
      "gnm6 \t 0.9994, 0.0004\n",
      "gnm7 \t 0.9994, 0.0004\n",
      "gnm8 \t 0.9995, 0.0004\n",
      "gnm9 \t 0.9994, 0.0004\n",
      "gnm10 \t 0.9995, 0.0004\n"
     ]
    }
   ],
   "source": [
    "mean_r2 = [np.mean(x[:, 5]) for x in d_cont2]\n",
    "std_r2 = [np.std(x[:, 5]) for x in d_cont2]\n",
    "\n",
    "for i, x in enumerate(zip(mean_r2, std_r2)):\n",
    "    print(title_cont2[i], '\\t' ,'%6.4f, %.4f' % tuple(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) P and p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, title in enumerate(title_cont2):\n",
    "    X_data = d_cont2[i][:, 2]\n",
    "    Y_data = d_cont2[i][:, 0]\n",
    "    to_fit = pd.DataFrame({'X':X_data,'Y':Y_data})\n",
    "    results = smf.ols('Y ~ X-1', data=to_fit).fit()\n",
    "    a = results.params['X']\n",
    "    r2 = results.rsquared\n",
    "    print('%s \\n R2: %.4f, beta: %.2f' %(title, r2, a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) Q and q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, title in enumerate(title_cont2):\n",
    "    X_data = d_cont2[i][:, 3]\n",
    "    Y_data = d_cont2[i][:, 1]\n",
    "    to_fit = pd.DataFrame({'X':X_data,'Y':Y_data})\n",
    "    results = smf.ols('Y ~ X-1', data=to_fit).fit()\n",
    "    a = results.params['X']\n",
    "    r2 = results.rsquared\n",
    "    print('%s \\n R2: %.4f, beta: %.2f' %(title, r2, a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 98.44s \n"
     ]
    }
   ],
   "source": [
    "res_dict2 = {}\n",
    "t1= time.clock()\n",
    "for i, title in enumerate(title_cont2):\n",
    "    res_cont = []\n",
    "    data = d_cont2[i]\n",
    "    for j in range(1000):\n",
    "        dis_train, dis_test = calcu_distance(data, num_train=9)      \n",
    "        res_cont.append([(np.mean(dis_train), np.std(dis_train)),\n",
    "                         (np.mean(dis_test), np.std(dis_test))])\n",
    "        \n",
    "    res_dict2[title] = res_cont\n",
    "print('Time elapsed: %.2fs ' % (time.clock() - t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gnm3\t  Train: 0.00047 (0.000117)\t  Test: 0.00097 (0.000250)\n",
      "gnm4\t  Train: 0.00158 (0.000229)\t  Test: 0.00033 (0.000125)\n",
      "gnm5\t  Train: 0.00058 (0.000190)\t  Test: 0.00041 (0.000080)\n",
      "gnm6\t  Train: 0.00069 (0.000280)\t  Test: 0.00045 (0.000139)\n",
      "gnm7\t  Train: 0.00049 (0.000160)\t  Test: 0.00050 (0.000163)\n",
      "gnm8\t  Train: 0.00063 (0.000137)\t  Test: 0.00056 (0.000153)\n",
      "gnm9\t  Train: 0.00042 (0.000164)\t  Test: 0.00028 (0.000025)\n",
      "gnm10\t  Train: 0.00031 (0.000123)\t  Test: 0.00036 (0.000075)\n"
     ]
    }
   ],
   "source": [
    "mean_dict2 = {}\n",
    "for i, title in enumerate(title_cont2):\n",
    "    d = res_dict2[title]\n",
    "    mean_train = d[:][0][0]\n",
    "    std_train = d[:][0][1]\n",
    "    \n",
    "    mean_test = d[:][1][0]\n",
    "    std_test = d[:][1][1]\n",
    "    \n",
    "    mean_dict2[title] = [mean_train, mean_test]\n",
    "    \n",
    "    print('%s' % title, end='\\t')\n",
    "    print('  Train: %.5f (%.6f)' % (np.mean(mean_train), np.std(mean_train)), end='\\t')\n",
    "    print('  Test: %.5f (%.6f)' % (np.mean(mean_test), np.std(mean_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (4) 和随机抽取点对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gnm3\t0.01776\tt-statistic = -67.225\t pvalue = 0.0095\n",
      "gnm4\t0.01489\tt-statistic = -116.576\t pvalue = 0.0055\n",
      "gnm5\t0.01334\tt-statistic = -161.440\t pvalue = 0.0039\n",
      "gnm6\t0.01248\tt-statistic = -86.341\t pvalue = 0.0074\n",
      "gnm7\t0.01280\tt-statistic = -75.508\t pvalue = 0.0084\n",
      "gnm8\t0.01233\tt-statistic = -76.733\t pvalue = 0.0083\n",
      "gnm9\t0.01090\tt-statistic = -427.449\t pvalue = 0.0015\n",
      "gnm10\t0.01126\tt-statistic = -144.842\t pvalue = 0.0044\n"
     ]
    }
   ],
   "source": [
    "for i, title in enumerate(title_cont2):\n",
    "    data = d_cont2[i]    \n",
    "    samp = mean_dict2[title][1]\n",
    "    x = grid_distance(data)\n",
    "    print('%s' % title, end='\\t')\n",
    "    print('%.5f' % x,  end='\\t')\n",
    "    print('t-statistic = %6.3f\\t pvalue = %6.4f' %  stats.ttest_1samp(samp, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. decision rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coeff_cont_gnm01 = np.load(u +\"estimate_gnm_random_graph(10000,30000),0.1.npy\")\n",
    "coeff_cont_gnm03 = np.load(u +\"estimate_gnm_random_graph(10000,30000),0.3.npy\")\n",
    "coeff_cont_gnm05 = np.load(u +\"estimate_gnm_random_graph(10000,30000),0.5.npy\")\n",
    "coeff_cont_gnm07 = np.load(u +\"estimate_gnm_random_graph(10000,30000),0.7.npy\")\n",
    "coeff_cont_gnm09 = np.load(u +\"estimate_gnm_random_graph(10000,30000),0.9.npy\")\n",
    "coeff_cont_gnm10 = np.load(u +\"estimate_gnm_random_graph(10000,30000),1.0.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_cont3 = [coeff_cont_gnm01,coeff_cont_gnm03,coeff_cont_gnm05,coeff_cont_gnm07,coeff_cont_gnm09,coeff_cont_gnm10]\n",
    "title_cont3 = ['alpha0.1', 'alpha0.3', 'alpha0.5', 'alpha0.7', 'alpha0.9', 'alpha1.0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha0.1 \t 0.9991, 0.0005\n",
      "alpha0.3 \t 0.9991, 0.0005\n",
      "alpha0.5 \t 0.9987, 0.0013\n",
      "alpha0.7 \t 0.9989, 0.0007\n",
      "alpha0.9 \t 0.9987, 0.0012\n",
      "alpha1.0 \t 0.9989, 0.0007\n"
     ]
    }
   ],
   "source": [
    "mean_r2 = [np.mean(x[:, 5]) for x in d_cont3]\n",
    "std_r2 = [np.std(x[:, 5]) for x in d_cont3]\n",
    "\n",
    "for i, x in enumerate(zip(mean_r2, std_r2)):\n",
    "    print(title_cont3[i], '\\t' ,'%6.4f, %.4f' % tuple(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) P and p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, title in enumerate(title_cont3):\n",
    "    X_data = d_cont3[i][:, 2]\n",
    "    Y_data = d_cont3[i][:, 0]\n",
    "    to_fit = pd.DataFrame({'X':X_data,'Y':Y_data})\n",
    "    results = smf.ols('Y ~ X-1', data=to_fit).fit()\n",
    "    a = results.params['X']\n",
    "    r2 = results.rsquared\n",
    "    print('%s \\n R2: %.4f, beta: %.2f' %(title, r2, a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) Q and q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, title in enumerate(title_cont3):\n",
    "    X_data = d_cont3[i][:, 3]\n",
    "    Y_data = d_cont3[i][:, 1]\n",
    "    to_fit = pd.DataFrame({'X':X_data,'Y':Y_data})\n",
    "    results = smf.ols('Y ~ X-1', data=to_fit).fit()\n",
    "    a = results.params['X']\n",
    "    r2 = results.rsquared\n",
    "    print('%s \\n R2: %.4f, beta: %.2f' %(title, r2, a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 75.92s \n"
     ]
    }
   ],
   "source": [
    "res_dict3 = {}\n",
    "t1= time.clock()\n",
    "for i, title in enumerate(title_cont3):\n",
    "    res_cont = []\n",
    "    data = d_cont3[i]\n",
    "    for j in range(1000):\n",
    "        dis_train, dis_test = calcu_distance(data, num_train=9)      \n",
    "        res_cont.append([(np.mean(dis_train), np.std(dis_train)),\n",
    "                         (np.mean(dis_test), np.std(dis_test))])\n",
    "    res_dict3[title] = res_cont\n",
    "print('Time elapsed: %.2fs ' % (time.clock() - t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha0.1\t  Train: 0.00146 (0.000262)\t  Test: 0.00135 (0.000448)\n",
      "alpha0.3\t  Train: 0.00181 (0.000662)\t  Test: 0.00262 (0.000272)\n",
      "alpha0.5\t  Train: 0.01008 (0.003014)\t  Test: 0.00284 (0.000171)\n",
      "alpha0.7\t  Train: 0.00553 (0.001758)\t  Test: 0.00328 (0.000827)\n",
      "alpha0.9\t  Train: 0.00719 (0.001705)\t  Test: 0.00935 (0.000711)\n",
      "alpha1.0\t  Train: 0.00445 (0.000480)\t  Test: 0.00448 (0.000904)\n"
     ]
    }
   ],
   "source": [
    "mean_dict3 = {}\n",
    "for i, title in enumerate(title_cont3):\n",
    "    d = res_dict3[title]\n",
    "    mean_train = d[:][0][0]\n",
    "    std_train = d[:][0][1]\n",
    "    \n",
    "    mean_test = d[:][1][0]\n",
    "    std_test = d[:][1][1]\n",
    "    \n",
    "    mean_dict3[title] = [mean_train, mean_test]\n",
    "    \n",
    "    print('%s' % title, end='\\t')\n",
    "    print('  Train: %.5f (%.6f)' % (np.mean(mean_train), np.std(mean_train)), end='\\t')\n",
    "    print('  Test: %.5f (%.6f)' % (np.mean(mean_test), np.std(mean_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (4) 和随机取点的对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha0.1\t0.01825\tt-statistic = -37.705 pvalue = 0.0169\n",
      "alpha0.3\t0.02385\tt-statistic = -78.009 pvalue = 0.0082\n",
      "alpha0.5\t0.03223\tt-statistic = -171.614 pvalue = 0.0037\n",
      "alpha0.7\t0.04457\tt-statistic = -49.937 pvalue = 0.0127\n",
      "alpha0.9\t0.06227\tt-statistic = -74.458 pvalue = 0.0085\n",
      "alpha1.0\t0.07358\tt-statistic = -76.425 pvalue = 0.0083\n"
     ]
    }
   ],
   "source": [
    "for i, title in enumerate(title_cont3):\n",
    "    data = d_cont3[i]\n",
    "    samp = mean_dict3[title][1]\n",
    "    x = grid_distance(data)\n",
    "    print('%s' % title, end='\\t')\n",
    "    print('%.5f' % x,  end='\\t')\n",
    "    print('t-statistic = %6.3f pvalue = %6.4f' %  stats.ttest_1samp(samp, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. individual heterogeneity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coeff_cont_sgima01 = np.load(u +\"estimate_sigma-0.1.npy\")\n",
    "coeff_cont_sgima02 = np.load(u +\"estimate_sigma-0.2.npy\")\n",
    "coeff_cont_sgima04 = np.load(u +\"estimate_sigma-0.4.npy\")\n",
    "coeff_cont_sgima06 = np.load(u +\"estimate_sigma-0.6.npy\")\n",
    "coeff_cont_sgima08 = np.load(u +\"estimate_sigma-0.8.npy\")\n",
    "coeff_cont_sgima10 = np.load(u +\"estimate_sigma-1.0.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_cont4 = [coeff_cont_sgima01,coeff_cont_sgima02,coeff_cont_sgima04,\n",
    "           coeff_cont_sgima06,coeff_cont_sgima08,coeff_cont_sgima10]\n",
    "title_cont4 = ['sigma0.1', 'sigma0.2', 'sigma0.4', 'sigma0.6', 'sigma0.8', 'sigma1.0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma0.1 \t 0.9991, 0.0005\n",
      "sigma0.2 \t 0.9992, 0.0005\n",
      "sigma0.4 \t 0.9989, 0.0006\n",
      "sigma0.6 \t 0.9987, 0.0007\n",
      "sigma0.8 \t 0.9985, 0.0009\n",
      "sigma1.0 \t 0.9985, 0.0010\n"
     ]
    }
   ],
   "source": [
    "mean_r2 = [np.mean(x[:, 5]) for x in d_cont4]\n",
    "std_r2 = [np.std(x[:, 5]) for x in d_cont4]\n",
    "\n",
    "for i, x in enumerate(zip(mean_r2, std_r2)):\n",
    "    print(title_cont4[i], '\\t' ,'%6.4f, %.4f' % tuple(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) P and p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, title in enumerate(title_cont4):\n",
    "    X_data = d_cont4[i][:, 2]\n",
    "    Y_data = d_cont4[i][:, 0]\n",
    "    to_fit = pd.DataFrame({'X':X_data,'Y':Y_data})\n",
    "    results = smf.ols('Y ~ X-1', data=to_fit).fit()\n",
    "    a = results.params['X']\n",
    "    r2 = results.rsquared\n",
    "    print('%s \\n R2: %.4f, beta: %.2f' %(title, r2, a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) Q and q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, title in enumerate(title_cont4):\n",
    "    X_data = d_cont4[i][:, 3]\n",
    "    Y_data = d_cont4[i][:, 1]\n",
    "    to_fit = pd.DataFrame({'X':X_data,'Y':Y_data})\n",
    "    results = smf.ols('Y ~ X-1', data=to_fit).fit()\n",
    "    a = results.params['X']\n",
    "    r2 = results.rsquared\n",
    "    print('%s \\n R2: %.4f, beta: %.2f' %(title, r2, a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 73.35s \n"
     ]
    }
   ],
   "source": [
    "res_dict4 = {}\n",
    "t1 = time.clock()\n",
    "for i, title in enumerate(title_cont4):\n",
    "    res_cont = []\n",
    "    data = d_cont4[i]\n",
    "    for j in range(1000):\n",
    "        dis_train, dis_test = calcu_distance(data, num_train=9)      \n",
    "        res_cont.append([(np.mean(dis_train), np.std(dis_train)),\n",
    "                         (np.mean(dis_test), np.std(dis_test))])\n",
    "        \n",
    "    res_dict4[title] = res_cont\n",
    "print('Time elapsed: %.2fs ' % (time.clock() - t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma0.1\t  Train: 0.00151 (0.000041)\t  Test: 0.00093 (0.000234)\n",
      "sigma0.2\t  Train: 0.00144 (0.000344)\t  Test: 0.00102 (0.000135)\n",
      "sigma0.4\t  Train: 0.00157 (0.000495)\t  Test: 0.00107 (0.000249)\n",
      "sigma0.6\t  Train: 0.00113 (0.000169)\t  Test: 0.00290 (0.000250)\n",
      "sigma0.8\t  Train: 0.00301 (0.000295)\t  Test: 0.00094 (0.000296)\n",
      "sigma1.0\t  Train: 0.00241 (0.000459)\t  Test: 0.00227 (0.000483)\n"
     ]
    }
   ],
   "source": [
    "mean_dict4 = {}\n",
    "for i, title in enumerate(title_cont4):\n",
    "    d = res_dict4[title]\n",
    "    mean_train = d[:][0][0]\n",
    "    std_train = d[:][0][1]\n",
    "    \n",
    "    mean_test = d[:][1][0]\n",
    "    std_test = d[:][1][1]\n",
    "    \n",
    "    mean_dict4[title] = [mean_train, mean_test]\n",
    "    \n",
    "    print('%s' % title, end='\\t')\n",
    "    print('  Train: %.5f (%.6f)' % (np.mean(mean_train), np.std(mean_train)), end='\\t')\n",
    "    print('  Test: %.5f (%.6f)' % (np.mean(mean_test), np.std(mean_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (4) 和随机取点的对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma0.1\t0.02131\tt-statistic = -87.197 pvalue = 0.0073\n",
      "sigma0.2\t0.02127\tt-statistic = -149.552 pvalue = 0.0043\n",
      "sigma0.4\t0.02084\tt-statistic = -79.453 pvalue = 0.0080\n",
      "sigma0.6\t0.02076\tt-statistic = -71.494 pvalue = 0.0089\n",
      "sigma0.8\t0.01818\tt-statistic = -58.256 pvalue = 0.0109\n",
      "sigma1.0\t0.01818\tt-statistic = -32.934 pvalue = 0.0193\n"
     ]
    }
   ],
   "source": [
    "for i, title in enumerate(title_cont4):\n",
    "    data = d_cont4[i]\n",
    "    samp = mean_dict4[title][1]\n",
    "    x = grid_distance(data)\n",
    "    print('%s' % title, end='\\t')\n",
    "    print('%.5f' % x,  end='\\t')\n",
    "    print('t-statistic = %6.3f pvalue = %6.4f' %  stats.ttest_1samp(samp, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 5. GMM decision rule (for online supplementary document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_gmm_3 = np.load(u +\"estimate_gnm_random_graph(10000,30000)-gmm.npy\")\n",
    "coeff_gmm_4 = np.load(u +\"estimate_gnm_random_graph(10000,40000)-gmm.npy\")\n",
    "coeff_gmm_5 = np.load(u +\"estimate_gnm_random_graph(10000,50000)-gmm.npy\")\n",
    "coeff_gmm_6 = np.load(u +\"estimate_gnm_random_graph(10000,60000)-gmm.npy\")\n",
    "coeff_gmm_7 = np.load(u +\"estimate_gnm_random_graph(10000,70000)-gmm.npy\")\n",
    "coeff_gmm_8 = np.load(u +\"estimate_gnm_random_graph(10000,80000)-gmm.npy\")\n",
    "coeff_gmm_9 = np.load(u +\"estimate_gnm_random_graph(10000,90000)-gmm.npy\")\n",
    "coeff_gmm_10 = np.load(u +\"estimate_gnm_random_graph(10000,100000)-gmm.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_cont5 = [coeff_gmm_3, coeff_gmm_4, coeff_gmm_5, coeff_gmm_6, coeff_gmm_7, coeff_gmm_8, coeff_gmm_9, coeff_gmm_10, ]\n",
    "title_cont5 = ['gmm6', 'gmm8', 'gmm10', 'gmm12', 'gmm14', 'gmm16', 'gmm18', 'gmm20']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gmm6 \t 0.9984, 0.0009\n",
      "gmm8 \t 0.9986, 0.0008\n",
      "gmm10 \t 0.9986, 0.0009\n",
      "gmm12 \t 0.9987, 0.0007\n",
      "gmm14 \t 0.9988, 0.0007\n",
      "gmm16 \t 0.9988, 0.0007\n",
      "gmm18 \t 0.9988, 0.0007\n",
      "gmm20 \t 0.9988, 0.0006\n"
     ]
    }
   ],
   "source": [
    "mean_r2 = [np.mean(x[:, 5]) for x in d_cont5]\n",
    "std_r2 = [np.std(x[:, 5]) for x in d_cont5]\n",
    "\n",
    "for i, x in enumerate(zip(mean_r2, std_r2)):\n",
    "    print(title_cont5[i], '\\t' ,'%6.4f, %.4f' % tuple(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) P and p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gmm6 \n",
      " R2: 0.9969, beta: 0.73\n",
      "gmm8 \n",
      " R2: 0.9972, beta: 0.75\n",
      "gmm10 \n",
      " R2: 0.9975, beta: 0.76\n",
      "gmm12 \n",
      " R2: 0.9973, beta: 0.78\n",
      "gmm14 \n",
      " R2: 0.9972, beta: 0.78\n",
      "gmm16 \n",
      " R2: 0.9972, beta: 0.78\n",
      "gmm18 \n",
      " R2: 0.9975, beta: 0.79\n",
      "gmm20 \n",
      " R2: 0.9977, beta: 0.79\n"
     ]
    }
   ],
   "source": [
    "for i, title in enumerate(title_cont5):\n",
    "    X_data = d_cont5[i][:, 2]\n",
    "    Y_data = d_cont5[i][:, 0]\n",
    "    to_fit = pd.DataFrame({'X':X_data,'Y':Y_data})\n",
    "    results = smf.ols('Y ~ X-1', data=to_fit).fit()\n",
    "    a = results.params['X']\n",
    "    r2 = results.rsquared\n",
    "    print('%s \\n R2: %.4f, beta: %.2f' %(title, r2, a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) q and Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gmm6 \n",
      " R2: 0.9992, beta: 0.21\n",
      "gmm8 \n",
      " R2: 0.9992, beta: 0.15\n",
      "gmm10 \n",
      " R2: 0.9988, beta: 0.12\n",
      "gmm12 \n",
      " R2: 0.9989, beta: 0.10\n",
      "gmm14 \n",
      " R2: 0.9990, beta: 0.09\n",
      "gmm16 \n",
      " R2: 0.9992, beta: 0.07\n",
      "gmm18 \n",
      " R2: 0.9992, beta: 0.07\n",
      "gmm20 \n",
      " R2: 0.9993, beta: 0.06\n"
     ]
    }
   ],
   "source": [
    "for i, title in enumerate(title_cont5):\n",
    "    X_data = d_cont5[i][:, 3]\n",
    "    Y_data = d_cont5[i][:, 1]\n",
    "    to_fit = pd.DataFrame({'X':X_data,'Y':Y_data})\n",
    "    results = smf.ols('Y ~ X-1', data=to_fit).fit()\n",
    "    a = results.params['X']\n",
    "    r2 = results.rsquared\n",
    "    print('%s \\n R2: %.4f, beta: %.2f' %(title, r2, a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 109.27s \n"
     ]
    }
   ],
   "source": [
    "res_dict5 = {}\n",
    "t1 = time.clock()\n",
    "for i, title in enumerate(title_cont5):\n",
    "    res_cont = []\n",
    "    data = d_cont5[i]\n",
    "    for j in range(1000):\n",
    "        dis_train, dis_test = calcu_distance(data, num_train=9)      \n",
    "        res_cont.append([(np.mean(dis_train), np.std(dis_train)),\n",
    "                         (np.mean(dis_test), np.std(dis_test))])\n",
    "        \n",
    "    res_dict5[title] = res_cont\n",
    "print('Time elapsed: %.2fs ' % (time.clock() - t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gmm6\t  Train: 0.00181 (0.000293)\t  Test: 0.00182 (0.000703)\n",
      "gmm8\t  Train: 0.00150 (0.000028)\t  Test: 0.00114 (0.000362)\n",
      "gmm10\t  Train: 0.00112 (0.000096)\t  Test: 0.00101 (0.000144)\n",
      "gmm12\t  Train: 0.00058 (0.000233)\t  Test: 0.00096 (0.000351)\n",
      "gmm14\t  Train: 0.00106 (0.000289)\t  Test: 0.00110 (0.000177)\n",
      "gmm16\t  Train: 0.00065 (0.000238)\t  Test: 0.00043 (0.000179)\n",
      "gmm18\t  Train: 0.00049 (0.000198)\t  Test: 0.00041 (0.000235)\n",
      "gmm20\t  Train: 0.00032 (0.000183)\t  Test: 0.00056 (0.000157)\n"
     ]
    }
   ],
   "source": [
    "mean_dict5 = {}\n",
    "for i, title in enumerate(title_cont5):\n",
    "    d = res_dict5[title]\n",
    "    mean_train = d[:][0][0]\n",
    "    std_train = d[:][0][1]\n",
    "    \n",
    "    mean_test = d[:][1][0]\n",
    "    std_test = d[:][1][1]\n",
    "    \n",
    "    mean_dict5[title] = [mean_train, mean_test]\n",
    "    \n",
    "    print('%s' % title, end='\\t')\n",
    "    print('  Train: %.5f (%.6f)' % (np.mean(mean_train), np.std(mean_train)), end='\\t')\n",
    "    print('  Test: %.5f (%.6f)' % (np.mean(mean_test), np.std(mean_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (4) 和随机取点的对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gmm6\t0.01827\tt-statistic = -23.405 pvalue = 0.0272\n",
      "gmm8\t0.01503\tt-statistic = -38.391 pvalue = 0.0166\n",
      "gmm10\t0.01321\tt-statistic = -84.792 pvalue = 0.0075\n",
      "gmm12\t0.01322\tt-statistic = -34.953 pvalue = 0.0182\n",
      "gmm14\t0.01236\tt-statistic = -63.776 pvalue = 0.0100\n",
      "gmm16\t0.01148\tt-statistic = -61.604 pvalue = 0.0103\n",
      "gmm18\t0.01099\tt-statistic = -45.117 pvalue = 0.0141\n",
      "gmm20\t0.01012\tt-statistic = -60.829 pvalue = 0.0105\n"
     ]
    }
   ],
   "source": [
    "for i, title in enumerate(title_cont5):\n",
    "    data = d_cont5[i]\n",
    "    samp = mean_dict5[title][1]\n",
    "    x = grid_distance(data)\n",
    "    print('%s' % title, end='\\t')\n",
    "    print('%.5f' % x,  end='\\t')\n",
    "    print('t-statistic = %6.3f pvalue = %6.4f' %  stats.ttest_1samp(samp, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. different points of data (for online supplementary document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coeff_peak_1 = np.load(u +\"estimate_gnm_random_graph(10000,30000)_Peak-1.npy\")\n",
    "coeff_peak0 =  np.load(u +\"estimate_gnm_random_graph(10000,30000)_Peak0.npy\")\n",
    "coeff_peak1 = np.load(u +\"estimate_gnm_random_graph(10000,30000)_Peak1.npy\")\n",
    "coeff_peak2 = np.load(u +\"estimate_gnm_random_graph(10000,30000)_Peak2.npy\")\n",
    "coeff_peak3 = np.load(u +\"estimate_gnm_random_graph(10000,30000)_Peak3.npy\")\n",
    "coeff_peak4 = np.load(u +\"estimate_gnm_random_graph(10000,30000)_Peak4.npy\")\n",
    "coeff_peak5 = np.load(u +\"estimate_gnm_random_graph(10000,30000)_Peak5.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_cont6 = [coeff_peak_1, coeff_peak0, coeff_peak1, coeff_peak2, coeff_peak3, coeff_peak4, coeff_peak5]\n",
    "title_cont6 = ['P-1', 'P', 'P+1', 'P+2', 'P+3', 'P+4', 'P+5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-1 \t 0.9996, 0.0004\n",
      "P \t 0.9995, 0.0003\n",
      "P+1 \t 0.9992, 0.0005\n",
      "P+2 \t 0.9984, 0.0009\n",
      "P+3 \t 0.9972, 0.0014\n",
      "P+4 \t 0.9958, 0.0019\n",
      "P+5 \t 0.9945, 0.0023\n"
     ]
    }
   ],
   "source": [
    "mean_r2 = [np.mean(x[:, 5]) for x in d_cont6]\n",
    "std_r2 = [np.std(x[:, 5]) for x in d_cont6]\n",
    "\n",
    "for i, x in enumerate(zip(mean_r2, std_r2)):\n",
    "    print(title_cont6[i], '\\t' ,'%6.4f, %.4f' % tuple(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  (2) p and P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-1, R2: 0.9984, beta: 0.78\n",
      "P, R2: 0.9987, beta: 0.80\n",
      "P+1, R2: 0.9986, beta: 0.81\n",
      "P+2, R2: 0.9981, beta: 0.80\n",
      "P+3, R2: 0.9975, beta: 0.79\n",
      "P+4, R2: 0.9970, beta: 0.78\n",
      "P+5, R2: 0.9965, beta: 0.77\n"
     ]
    }
   ],
   "source": [
    "for i, title in enumerate(title_cont6):\n",
    "    X_data = d_cont6[i][:, 2]\n",
    "    Y_data = d_cont6[i][:, 0]\n",
    "    to_fit = pd.DataFrame({'X':X_data,'Y':Y_data})\n",
    "    results = smf.ols('Y ~ X-1', data=to_fit).fit()\n",
    "    a = results.params['X']\n",
    "    r2 = results.rsquared\n",
    "    print('%s, R2: %.4f, beta: %.2f' %(title, r2, a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) q and Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-1, R2: 0.9984, beta: 0.19\n",
      "P, R2: 0.9990, beta: 0.19\n",
      "P+1, R2: 0.9991, beta: 0.20\n",
      "P+2, R2: 0.9993, beta: 0.20\n",
      "P+3, R2: 0.9992, beta: 0.21\n",
      "P+4, R2: 0.9992, beta: 0.21\n",
      "P+5, R2: 0.9993, beta: 0.22\n"
     ]
    }
   ],
   "source": [
    "for i, title in enumerate(title_cont6):\n",
    "    X_data = d_cont6[i][:, 3]\n",
    "    Y_data = d_cont6[i][:, 1]\n",
    "    to_fit = pd.DataFrame({'X':X_data,'Y':Y_data})\n",
    "    results = smf.ols('Y ~ X-1', data=to_fit).fit()\n",
    "    a = results.params['X']\n",
    "    r2 = results.rsquared\n",
    "    print('%s, R2: %.4f, beta: %.2f' %(title, r2, a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (4) Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res_dict6 = {}\n",
    "for i, title in enumerate(title_cont6):\n",
    "    res_cont = []\n",
    "    data = d_cont6[i]\n",
    "    for j in range(1000):\n",
    "        dis_train, dis_test = calcu_distance(data, num_train=9)      \n",
    "        res_cont.append([(np.mean(dis_train), np.std(dis_train)),\n",
    "                         (np.mean(dis_test), np.std(dis_test))])\n",
    "    res_dict6[title] = res_cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-1\t  Train: 0.00217 (0.000474)\t  Test: 0.00140 (0.000403)\n",
      "P\t  Train: 0.00057 (0.000105)\t  Test: 0.00108 (0.000277)\n",
      "P+1\t  Train: 0.00097 (0.000198)\t  Test: 0.00086 (0.000332)\n",
      "P+2\t  Train: 0.00095 (0.000295)\t  Test: 0.00079 (0.000150)\n",
      "P+3\t  Train: 0.00162 (0.000387)\t  Test: 0.00062 (0.000206)\n",
      "P+4\t  Train: 0.00129 (0.000477)\t  Test: 0.00099 (0.000245)\n",
      "P+5\t  Train: 0.00156 (0.000484)\t  Test: 0.00088 (0.000201)\n"
     ]
    }
   ],
   "source": [
    "mean_dict6 = {}\n",
    "for i, title in enumerate(title_cont6):\n",
    "    d = res_dict6[title]\n",
    "    \n",
    "    mean_train = d[:][0][0]\n",
    "    std_train = d[:][0][1]\n",
    "    \n",
    "    mean_test = d[:][1][0]\n",
    "    std_test = d[:][1][1]\n",
    "    \n",
    "    mean_dict6[title] = [mean_train, mean_test]\n",
    "    \n",
    "    print('%s' % title, end='\\t')\n",
    "    print('  Train: %.5f (%.6f)' % (np.mean(mean_train), np.std(mean_train)), end='\\t')\n",
    "    print ('  Test: %.5f (%.6f)' % (np.mean(mean_test), np.std(mean_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (4) 和随机取点的对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-1\t0.01775\tt-statistic = -40.572\t pvalue = 0.0157\n",
      "P\t0.01769\tt-statistic = -59.975\t pvalue = 0.0106\n",
      "P+1\t0.01769\tt-statistic = -50.770\t pvalue = 0.0125\n",
      "P+2\t0.01776\tt-statistic = -113.437\t pvalue = 0.0056\n",
      "P+3\t0.01772\tt-statistic = -82.929\t pvalue = 0.0077\n",
      "P+4\t0.01772\tt-statistic = -68.193\t pvalue = 0.0093\n",
      "P+5\t0.01770\tt-statistic = -83.693\t pvalue = 0.0076\n"
     ]
    }
   ],
   "source": [
    "for i, title in enumerate(title_cont6):\n",
    "    data = d_cont6[i]\n",
    "    samp = mean_dict6[title][1]\n",
    "    x = grid_distance(data)\n",
    "    print('%s' % title, end='\\t')\n",
    "    print('%.5f' % x, end='\\t')\n",
    "    print('t-statistic = %6.3f\\t pvalue = %6.4f' %  stats.ttest_1samp(samp, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
